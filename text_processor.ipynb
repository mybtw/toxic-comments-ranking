{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4dd8bd7a80a0d9",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from html.parser import HTMLParser\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import string\n",
    "import fasttext\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from spacy.lang.ru import Russian\n",
    "import concurrent.futures\n",
    "\n",
    "contractions = {\n",
    "    \"и т.д.\": \" и так далее \",\n",
    "    \"и т.п.\": \" и тому подобное \",\n",
    "    \"ул.\": \" улица \"\n",
    "}\n",
    "\n",
    "nlp = spacy.load('ru_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b512259250e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHTMLParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.extracted_data = []\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        self.extracted_data.append(data)\n",
    "\n",
    "    def get_data(self):\n",
    "        return ''.join(self.extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_cyrillic(text):\n",
    "    # Удаляем все, кроме русских букв\n",
    "    return re.sub(r'[^а-яА-ЯёЁ]', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb61322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_r_with_rubles(text):\n",
    "    # Замена \"р\" после числа\n",
    "    text = re.sub(r'(\\d)р\\b', r'\\1 рублей ', text)\n",
    "    # Замена \"р\" перед числом\n",
    "    text = re.sub(r'\\bр(\\d)', r' рублей \\1', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_currency_symbols(text):\n",
    "    # Словарь символов валют и их полных названий\n",
    "    currency_symbols = {\n",
    "        r'\\$': ' долларов ',\n",
    "        r'€': ' евро ',\n",
    "        r'£': ' фунтов ',\n",
    "        r'¥': ' йен ',\n",
    "        r'₽': ' рублей '\n",
    "    }\n",
    "    \n",
    "    # Перебираем словарь и заменяем каждый символ валюты в тексте\n",
    "    for symbol, name in currency_symbols.items():\n",
    "        text = re.sub(symbol, name, text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_list_comp(text):\n",
    "    return re.sub(r'\\s+', ' ', re.sub(r'[\\s{}]+'.format(re.escape(string.punctuation)), ' ', text)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contractions_dict):\n",
    "    for key, value in contractions_dict.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_units_with_full_names(text):\n",
    "    # Словарь замен: сокращение единицы измерения и его полное словесное представление\n",
    "    units = {\n",
    "        'кг': 'килограмм',\n",
    "        'г': 'грамм',\n",
    "        'м': 'метр',\n",
    "        'см': 'сантиметр',\n",
    "        'мм': 'миллиметр',\n",
    "        'л': 'литр',\n",
    "        'мл': 'миллилитр',\n",
    "        'ч': 'час',\n",
    "        'мин': 'минута',\n",
    "        'сек': 'секунда',\n",
    "        'км': 'километр',\n",
    "        'шт': 'штук'\n",
    "    }\n",
    "    \n",
    "    for unit, full_name in units.items():\n",
    "        text = text.replace(f' {unit} ', f' {full_name} ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hyphens(text):\n",
    "    # Замена дефиса на минус в математических выражениях\n",
    "    text = re.sub(r'(?<=\\d)\\-(?=\\d)', ' минус ', text)  # между цифрами\n",
    "    text = re.sub(r'(?<=\\s)\\-(?=\\d)', ' минус ', text)  # перед числом после пробела\n",
    "    \n",
    "    # Замена дефиса на тире, учитывая контексты, где дефис не заменяется (например, частицы)\n",
    "    # Различие между тире и дефисом в частицах (например, \"что-то\", \"кто-либо\")\n",
    "    text = re.sub(r'\\b(\\w+)-(то|либо|нибудь|таки|ка)\\b', r'\\1-\\2', text)\n",
    "\n",
    "    # Общее правило замены дефиса на тире, если это не частицы\n",
    "    text = re.sub(r'(?<!\\w)(\\w+)-(\\w+)', r'\\1 дефис \\2', text)\n",
    "\n",
    "    # Замена дефиса на тире в прочих случаях\n",
    "    text = re.sub(r'(?<=\\s)-(?=\\s)', ' дефис ', text)  # между пробелами\n",
    "    text = re.sub(r'(?<=\\w)-(?=\\s)', ' дефис ', text)  # после слова перед пробелом\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces_regex(text):\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_identifiers(text):\n",
    "    # Регулярное выражение, которое ищет шестнадцатеричные хеши, UUIDs и другие типичные идентификаторы\n",
    "    pattern = r'\\b([a-f0-9]{32}|[a-f0-9]{40}|[a-f0-9]{64}|[a-f0-9-]{36}|[a-zA-Z0-9-]{7,})\\b'\n",
    "    \n",
    "    # Заменяем найденные идентификаторы на слово \"идентификатор\"\n",
    "    return re.sub(pattern, ' идентификатор ', text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_phone_numbers_and_digits(text):\n",
    "    # Регулярное выражение для номеров телефонов\n",
    "    phone_pattern = r'\\+?\\d[\\d\\-\\(\\)\\.\\s]{8,}\\d'\n",
    "    \n",
    "    # Заменить номера телефонов на \"номер телефона\"\n",
    "    text = re.sub(phone_pattern, ' номер телефона ', text)\n",
    "\n",
    "    text = replace_identifiers(text)\n",
    "    \n",
    "    # Заменить оставшиеся числа на \"число\"\n",
    "    text = re.sub(r'\\b\\d+\\b', ' число ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_custom_text_emojis(text):\n",
    "    # Словарь текстовых эмодзи и их словесных описаний\n",
    "    emoji_dict = {\n",
    "        r':\\)': ' улыбка ',\n",
    "        r':\\(': ' грустное лицо ',\n",
    "        r':D': ' смех ',\n",
    "        r';\\)': ' подмигивание '\n",
    "    }\n",
    "    \n",
    "    # Перебираем словарь и заменяем каждый эмодзи в тексте\n",
    "    for emoji, description in emoji_dict.items():\n",
    "        text = re.sub(emoji, description, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19334067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_math_symbols_with_words(text):\n",
    "    # Словарь замен: математический символ и его словесное представление\n",
    "    math_symbols = {\n",
    "        '+': ' плюс ',\n",
    "        '*': ' умножить на ',\n",
    "        '/': ' разделить на ',\n",
    "        '=': ' равно ',\n",
    "        '<': ' меньше ',\n",
    "        '>': ' больше ',\n",
    "        '≤': ' меньше или равно ',\n",
    "        '≥': ' больше или равно '\n",
    "    }\n",
    "    \n",
    "    # Перебираем словарь и заменяем каждый символ в тексте\n",
    "    for symbol, word in math_symbols.items():\n",
    "        text = text.replace(symbol, word)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d872864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_slang(text):\n",
    "    # Словарь замен: сленг и его нормальное представление\n",
    "    slang_dict = {\n",
    "        r'\\bтг\\b': ' телефон ',\n",
    "        r'\\bспс\\b': ' спасибо ',\n",
    "        r'\\bплиз\\b': ' пожалуйста ',\n",
    "        r'\\bчел\\b': ' человек ',\n",
    "        r'\\bкек\\b': ' смешно ',\n",
    "        r'\\bлол\\b': ' смешно '\n",
    "    }\n",
    "    \n",
    "    # Перебираем словарь и заменяем каждый сленг в тексте\n",
    "    for slang, normal in slang_dict.items():\n",
    "        text = re.sub(slang, normal, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "   # text = replace_hyphens(text)\n",
    "\n",
    "    #print(\"hyphens \", text)\n",
    "\n",
    "    text = replace_slang(text)\n",
    "\n",
    "    #print(\"slang \", text)\n",
    "\n",
    "    text = replace_custom_text_emojis(text)\n",
    "\n",
    "    #print(\"emoji \", text)\n",
    "\n",
    "    text = replace_r_with_rubles(text)\n",
    "\n",
    "    #print(\"rubles \", text)\n",
    "\n",
    "    text = replace_currency_symbols(text)\n",
    "\n",
    "    #print(\"currency \", text)\n",
    "\n",
    "    text = replace_phone_numbers_and_digits(text)\n",
    "\n",
    "    #print(\"phone_numbers_and_digits \", text)\n",
    "\n",
    "    # Перевод в нижний регистр\n",
    "\n",
    "    \n",
    "    # Раскрытие сокращений\n",
    "    text = expand_contractions(text, contractions)\n",
    "\n",
    "    \"\"\"   url_pattern = re.compile(\n",
    "    r'\\b(?:https?|ftp|mailto|data|tel):\\/\\/'  # Расширенные схемы\n",
    "    r'(?:(?:[a-z0-9-]+\\.)+[a-z]{2,13})'  # Доменное имя\n",
    "    r'(?:\\/[\\w\\-\\.~:+\\/?#\\[\\]@!$&\\'()*;,=]*)?'  # Путь\n",
    "    r'(?:(?:\\?[\\w\\-\\.~:+\\/?#\\[\\]@!$&\\'()*;,=]*)?)'  # Параметры\n",
    "    r'(?:(?:#[\\w\\-]*)?)\\b',  # Якорь\n",
    "    re.IGNORECASE)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    url_pattern = re.compile(r'https?://(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}')\n",
    "\n",
    "    # Удаление ссылок\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "\n",
    "    #print(\"links \", text)\n",
    "\n",
    "    # переводим эмоджи в текст вида :машет_рукой: , заменяем символы : и _ на пробелы\n",
    "    text = emoji.demojize(text, language='ru').replace(':', ' ').replace('_', ' ')\n",
    "\n",
    "    #print(\"emoji  \", text)\n",
    "    \n",
    "    # Обработка HTML\n",
    "    parser = MyHTMLParser()\n",
    "    parser.feed(text)\n",
    "    extracted_text = parser.get_data()\n",
    "    # Рекурсивно применяем функцию к извлеченному тексту\n",
    "    if extracted_text != text:  # Проверяем, был ли HTML тег\n",
    "        text = preprocess_text(extracted_text)\n",
    "    \n",
    "    #print(\"html  \", text)\n",
    "    \n",
    "    # убираем знаки пунктуации\n",
    "    text = remove_punctuation_list_comp(replace_math_symbols_with_words(text))\n",
    "\n",
    "    #print(\"remove_punctuation_list_comp  \", text)\n",
    "\n",
    "    text = replace_units_with_full_names(text)\n",
    "\n",
    "    #print(\"replace_units_with_full_names  \", text)\n",
    "\n",
    "    text = remove_extra_spaces_regex(remove_non_cyrillic(text))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_texts(texts):\n",
    "    lemmatized_texts = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "        lemmatized_texts.append(lemmatized_text)\n",
    "    return lemmatized_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_and_lemmatize(input_file_path, output_file_path):\n",
    "    # Загрузка данных из CSV файла\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    # Проверяем наличие нужного столбца\n",
    "    if 'processed_comment' not in df.columns:\n",
    "        raise ValueError(\"В файле отсутствует столбец 'processed_comment'.\")\n",
    "\n",
    "    # Пакетная лемматизация всех комментариев\n",
    "    df['lemmatized_comment'] = lemmatize_texts(df['processed_comment'])\n",
    "\n",
    "    # Сохраняем обновленный DataFrame в новый CSV файл\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    print(\"Файл успешно сохранен:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06840f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \" Привет :D Как дела? :) Надеюсь,  ) всё?хорошо:($100, €75, £50, f wa awfx спс ¥ 5000 и ₽3000 Ваш апи.ключ: abcd1234 ef5678gh, ваш UUID: 123e4567-e89b-12d3-a456-426614174000. +7 123 456-78-90 или (123) 456 7890. Возраст 30 лет Это пример текста с сокращениями типа кг и т.д. и HTML + <b>тегами</b>. Подробнее на www.foufos.gr  Привет 👋! Я рад этому дню 😊\"\n",
    "processed_text = preprocess_text(sample_text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_potential_contractions(file_path, column_name='comments'):\n",
    "    # Регулярное выражение для поиска потенциальных сокращений\n",
    "    contractions_pattern = re.compile(r'\\b\\w+\\.\\b')\n",
    "    \n",
    "    # Загрузка данных из файла\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Убедимся, что колонка с комментариями существует\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Колонка {column_name} не найдена в файле.\")\n",
    "    \n",
    "    # Поиск потенциальных сокращений в каждом комментарии\n",
    "    df['potential_contractions'] = df[column_name].apply(lambda x: re.findall(contractions_pattern, x))\n",
    "    \n",
    "    return df[df['potential_contractions'].map(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataset/dataset-ru2.csv'\n",
    "result_df = find_potential_contractions(file_path, 'comment')\n",
    "result_df.to_csv('dataset/look2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b31ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_add_column(input_file_path, output_file_path):\n",
    "    # Загрузка данных из CSV файла\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    if 'comment' not in df.columns:\n",
    "        raise ValueError(\"В файле отсутствует столбец 'comment'.\")\n",
    "\n",
    "    df['processed_comment'] = df['comment'].apply(preprocess_text)\n",
    "    \n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    print(\"Файл успешно сохранен:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eaac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'dataset/dataset_lg.csv'  # Укажите здесь путь к вашему файлу\n",
    "output_file = 'dataset/dataset_lg_train.csv'  # Путь для сохранения нового файла\n",
    "\n",
    "process_csv_add_column(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eced9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'dataset_lg_train.csv'\n",
    "output_file_path = 'dataset/dataset_lg_train_final.csv'\n",
    "process_csv_and_lemmatize(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/train-ru2-lemmatized.csv')\n",
    "print(df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('train-ru-lemmatized.csv')\n",
    "\n",
    "# Выбор столбца (замените 'column_name' на имя вашего столбца)\n",
    "column = df['lemmatized_comment']\n",
    "\n",
    "unique_words = set()\n",
    "\n",
    "# Подсчёт слов в каждой строке столбца\n",
    "df['word_count'] = column.apply(lambda x: unique_words.update(str(x).lower().split()))\n",
    "\n",
    "# Подсчёт общего количества слов в столбце\n",
    "print(column.apply(lambda x: len(str(x))).max())\n",
    "\n",
    "print(column.apply(lambda x: len(str(x))).mean())\n",
    "\n",
    "print(\"Общее количество слов в столбце:\", len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b700704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-ru-lemmatized.csv')\n",
    "\n",
    "df['word_count'] = df['lemmatized_comment'].str.split().apply(len)\n",
    "\n",
    "# Нахождение индекса ячейки с наибольшим количеством слов\n",
    "max_words_index = df['word_count'].idxmax()\n",
    "\n",
    "# Вывод ячейки с наибольшим количеством слов\n",
    "print(\"Ячейка с наибольшим количеством слов:\")\n",
    "print(df.loc[max_words_index, 'lemmatized_comment'])\n",
    "\n",
    "# Вывод всей строки, если нужно больше информации\n",
    "print(\"\\nСтрока с наибольшим количеством слов:\")\n",
    "print(df.loc[max_words_index])\n",
    "print(df['comment'][250236])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-ru-lemmatized.csv')\n",
    "df['word_count'] = df['lemmatized_comment'].str.split().apply(len)\n",
    "\n",
    "# Вычисление среднего количества слов\n",
    "average_word_count = df['word_count'].mean()\n",
    "\n",
    "print(\"Среднее количество слов в ячейке:\", average_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset/dataset-ru1.csv')\n",
    "\n",
    "# Загрузка данных из второго CSV-файла\n",
    "df2 = pd.read_csv('dataset/dataset-ru2.csv')\n",
    "\n",
    "# Объединение DataFrame\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Сохранение объединенного DataFrame в новый CSV-файл\n",
    "combined_df.to_csv('dataset/dataset_lg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ee6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    # Обработка одного текста через nlp\n",
    "    doc = nlp(text)\n",
    "    # Создание лемматизированной строки\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a45484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lemmatize_text('вот прям бесят их песни аж блевать всегда хочется клоун'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977868eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dataset/dataset-ru2.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad558f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка файлов\n",
    "df1 = pd.read_csv('dataset/dataset-ru1.csv')\n",
    "df2 = pd.read_csv('dataset/dataset-ru2.csv')\n",
    "\n",
    "# Объединение файлов\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Сохранение объединенного файла\n",
    "combined_df.to_csv('dataset/dataset-ru.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642762f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('dataset/dataset-ru3.csv')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2185cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['comment'][239000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['preprocessed_comment'] = df2['comment'].apply(preprocess_text)\n",
    "\n",
    "# Сохранение обновлённого DataFrame в новый CSV файл\n",
    "df2.to_csv('updated_file-april.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df2['preprocessed_comment'].duplicated(keep=False)\n",
    "\n",
    "# Вывод строк с дублирующимися значениями\n",
    "duplicate_rows = df2[duplicates]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fe592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids = df2[\"preprocessed_comment\"]\n",
    "df2[ids.isin(ids[ids.duplicated()])].sort_values(\"preprocessed_comment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('dataset/dataset_lg_train.csv')\n",
    "df.dropna(inplace=True)\n",
    "unique_words = set()\n",
    "\n",
    "# Проход по каждой строке колонки и добавление слов в множество\n",
    "for comment in df2['processed_comment']:\n",
    "    # Делаем сплит по пробелу и добавляем результат в множество\n",
    "    unique_words.update(comment.split())\n",
    "\n",
    "# Вывод количества уникальных слов\n",
    "print(\"Количество уникальных слов:\", len(unique_words))\n",
    "#print(list(unique_words)[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('dataset/dataset_lg_train.csv')\n",
    "\n",
    "# Удаление строк с пропущенными значениями\n",
    "df2.dropna(inplace=True)\n",
    "\n",
    "# Создание множества для уникальных слов\n",
    "unique_words = set()\n",
    "\n",
    "# Проход по каждой строке колонки и добавление слов в множество\n",
    "for comment in df2['processed_comment']:\n",
    "    # Делаем сплит по пробелу и добавляем результат в множество\n",
    "    unique_words.update(comment.split())\n",
    "\n",
    "# Вывод количества уникальных слов\n",
    "print(\"Количество уникальных слов:\", len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bcaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/dataset-ru2.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "248283 + 14412"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
